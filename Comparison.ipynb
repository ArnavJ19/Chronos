{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72879f8",
   "metadata": {},
   "source": [
    "## Comparison between AutoARIMA and Amazon Chronos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f1109",
   "metadata": {},
   "source": [
    " ### Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ec714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and combine Date + Time as datetime index\n",
    "df = pd.read_csv(\n",
    "    'household_power_consumption.txt',\n",
    "    sep=';',\n",
    "    parse_dates={'datetime': ['Date', 'Time']},\n",
    "    infer_datetime_format=True,\n",
    "    na_values='?',\n",
    "    index_col='datetime',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Convert all numeric columns to float32\n",
    "df = df.astype('float32')\n",
    "df.sort_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74a658",
   "metadata": {},
   "source": [
    "### Step 2: Resample to Hourly Frequency\n",
    "\n",
    "We’ll resample the data to hourly frequency by taking the mean of all 1-minute readings per hour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d470f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to hourly frequency using mean aggregation\n",
    "df_hourly = df.resample('H').mean()\n",
    "\n",
    "# Focus only on the target variable\n",
    "df_hourly = df_hourly[['Global_active_power']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659c576",
   "metadata": {},
   "source": [
    "### Step 3: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c429c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values via linear interpolation\n",
    "df_hourly['Global_active_power'] = df_hourly['Global_active_power'].interpolate(method='linear')\n",
    "\n",
    "# Drop remaining NaNs if any\n",
    "df_hourly.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59264384",
   "metadata": {},
   "source": [
    "### Step 4: Train/Test Split\n",
    "Let’s split using 80% train / 20% test, preserving time order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% training / 20% test split\n",
    "split_index = int(len(df_hourly) * 0.8)\n",
    "train = df_hourly.iloc[:split_index]\n",
    "test = df_hourly.iloc[split_index:]\n",
    "\n",
    "# Separate into target arrays\n",
    "y_train = train['Global_active_power']\n",
    "y_test = test['Global_active_power']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d58bff7",
   "metadata": {},
   "source": [
    "### Step 5: Preparing data for Chronos & AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_df = df_hourly.copy().reset_index()\n",
    "chronos_df['item_id'] = 'household_1'\n",
    "chronos_df.columns = ['timestamp', 'target_value', 'item_id']\n",
    "\n",
    "# Reorder columns\n",
    "chronos_df = chronos_df[['item_id', 'timestamp', 'target_value']]\n",
    "\n",
    "# Save for HuggingFace Chronos interface or tokenization\n",
    "chronos_df.to_csv('chronos_input.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90990c92",
   "metadata": {},
   "source": [
    "### Forecasting using Amazon Chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ea1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from chronos import BaseChronosPipeline\n",
    "\n",
    "# Load pre-trained Chronos model (change to chronos-bolt-small for faster inference)\n",
    "pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-large\",  \n",
    "    device_map=\"cuda\",  # use \"cpu\" if no GPU\n",
    "    torch_dtype=torch.bfloat16,  # torch.float32 if bfloat16 unsupported\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed CSV used earlier\n",
    "df = pd.read_csv(\"chronos_input.csv\")\n",
    "\n",
    "# Extract the numeric values\n",
    "series = df[df['item_id'] == 'household_1']['target_value'].values\n",
    "\n",
    "# Define input context and prediction length\n",
    "prediction_length = 24\n",
    "max_possible = len(series) - prediction_length\n",
    "context_tensor = torch.tensor(series[-(max_possible + prediction_length):-prediction_length])\n",
    "\n",
    "# Run prediction\n",
    "quantiles, mean = pipeline.predict_quantiles(\n",
    "    context=context_tensor,\n",
    "    prediction_length=prediction_length,\n",
    "    quantile_levels=[0.1, 0.5, 0.9],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea70920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIG ===\n",
    "plot_context_length = 96         # Show last 96 hours of context\n",
    "prediction_length = 24           # Forecast horizon\n",
    "\n",
    "# === CONVERT TO NUMPY ARRAYS ===\n",
    "context_np = context_tensor.detach().cpu().numpy()\n",
    "mean_np = mean[0].detach().cpu().numpy()\n",
    "p10 = quantiles[0, :, 0].detach().cpu().numpy()\n",
    "p90 = quantiles[0, :, 2].detach().cpu().numpy()\n",
    "\n",
    "# === GROUND TRUTH ===\n",
    "# Ensure y_test only contains the last 24 values of the full series\n",
    "# (Replace 'series' with your actual NumPy array of the time series)\n",
    "y_test = series[-prediction_length:]\n",
    "\n",
    "# === CREATE X AXES ===\n",
    "context_display = context_np[-plot_context_length:]  # show only last 96 hours\n",
    "x_context = np.arange(plot_context_length)\n",
    "x_forecast = np.arange(plot_context_length, plot_context_length + prediction_length)\n",
    "\n",
    "# === PLOT ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot last 96 hours of context\n",
    "plt.plot(x_context, context_display, label='Training Context (last 96h)', color='blue')\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(x_forecast, y_test, label='Actual', color='black')\n",
    "\n",
    "# Plot Chronos mean forecast\n",
    "plt.plot(x_forecast, mean_np, label='Chronos Forecast (mean)', color='green')\n",
    "\n",
    "# Plot P10–P90 interval\n",
    "plt.fill_between(x_forecast, p10, p90, color='lightgreen', alpha=0.5, label='P10–P90 Interval')\n",
    "\n",
    "# Styling\n",
    "plt.title(\"Chronos Forecast vs. Actual (24-Hour Horizon, 96h Context)\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Global Active Power (kW)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d640ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Convert Chronos mean forecast to NumPy\n",
    "chronos_pred = mean[0].detach().cpu().numpy()  # shape: [prediction_length]\n",
    "\n",
    "# Ensure ground truth is a NumPy array (from earlier test split)\n",
    "# y_test = series[-prediction_length:]  # already defined in Part 5\n",
    "\n",
    "# Compute metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, chronos_pred))\n",
    "mae = mean_absolute_error(y_test, chronos_pred)\n",
    "mape = np.mean(np.abs((y_test - chronos_pred) / y_test)) * 100\n",
    "\n",
    "# Display\n",
    "print(f\"Chronos Forecast Accuracy:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b5370",
   "metadata": {},
   "source": [
    "### Forecasting using AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "prediction_length = 24\n",
    "plot_context_length = 96\n",
    "max_context_window = 1024\n",
    "csv_path = 'chronos_input.csv'\n",
    "\n",
    "# === STEP 1: Load Chronos CSV ===\n",
    "df = pd.read_csv(csv_path)\n",
    "series = df[df['item_id'] == 'household_1']['target_value'].values\n",
    "\n",
    "# === STEP 2: Split Series Properly ===\n",
    "y_train = series[-(prediction_length + max_context_window):-prediction_length]\n",
    "y_test = series[-prediction_length:]\n",
    "\n",
    "# === STEP 3: Train AutoARIMA ===\n",
    "model = auto_arima(\n",
    "    y_train,\n",
    "    start_p=0, max_p=5,       # AR terms\n",
    "    start_q=0, max_q=5,       # MA terms\n",
    "    d=None,                   # Let it determine differencing\n",
    "    seasonal=True,\n",
    "    start_P=0, max_P=2,\n",
    "    start_Q=0, max_Q=2,\n",
    "    D=None,\n",
    "    m=24,                     # Daily seasonality for hourly data\n",
    "    stepwise=False,           # Enable full grid search\n",
    "    error_action='ignore',\n",
    "    suppress_warnings=True,\n",
    "    method='lbfgs',\n",
    "    trace=True\n",
    ")\n",
    "\n",
    "\n",
    "# === STEP 4: Forecast ===\n",
    "forecast = model.predict(n_periods=prediction_length)\n",
    "\n",
    "# === STEP 5: Evaluation ===\n",
    "rmse = np.sqrt(mean_squared_error(y_test, forecast))\n",
    "mae = mean_absolute_error(y_test, forecast)\n",
    "mape = np.mean(np.abs((y_test - forecast) / y_test)) * 100\n",
    "\n",
    "print(\"AutoARIMA Forecast Accuracy:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# === STEP 6: Plot (last 96h of training + forecast) ===\n",
    "context_display = y_train[-plot_context_length:]\n",
    "x_context = np.arange(plot_context_length)\n",
    "x_forecast = np.arange(plot_context_length, plot_context_length + prediction_length)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_context, context_display, label='Training Context (last 96h)', color='blue')\n",
    "plt.plot(x_forecast, y_test, label='Actual', color='black')\n",
    "plt.plot(x_forecast, forecast, label='AutoARIMA Forecast', color='red')\n",
    "plt.title(\"AutoARIMA Forecast vs. Actual (24-Hour Horizon, 1024h Context)\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Global Active Power (kW)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ccca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc13d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
